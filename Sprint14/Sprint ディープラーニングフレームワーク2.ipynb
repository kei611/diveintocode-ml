{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 公式Example\n",
    "\n",
    "深層学習フレームワークには公式に様々なモデルのExampleコードが公開されています。\n",
    "\n",
    "## 【問題1】公式チュートリアルモデルを分担して実行\n",
    "TensorFLowの公式チュートリアルモデルを分担して実行してください。\n",
    "\n",
    "\n",
    "以下の中から1人ひとつ選び実行し、その結果を簡単に発表してください。\n",
    "\n",
    "\n",
    "models/tutorials at master · tensorflow/models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  [カスタムレイヤー](https://www.tensorflow.org/tutorials/customization/custom_layers#%E3%83%A2%E3%83%87%E3%83%AB%EF%BC%9A%E3%83%AC%E3%82%A4%E3%83%A4%E3%83%BC%E3%81%AE%E7%B5%84%E3%81%BF%E5%90%88%E3%82%8F%E3%81%9B)\n",
    "\n",
    "ニューラルネットワークの構築には、ハイレベルの API である tf.keras を使うことを推奨します。しかしながら、TensorFlow API のほとんどは、eager execution でも使用可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### レイヤー：有用な演算の共通セット\n",
    "機械学習モデルのコーディングでは、個々の演算やひとつひとつの変数のオペレーションよりは、より高度に抽象化されたオペレーションを行いたいのがほとんどだと思います。\n",
    "\n",
    "多くの機械学習モデルは、比較的単純なレイヤーの組み合わせや積み重ねによって表現可能です。TensorFlow では、多くの一般的なレイヤーのセットに加えて、アプリケーションに特有なレイヤーを最初から記述したり、既存のレイヤーの組み合わせによって作るための、簡単な方法が提供されています。\n",
    "\n",
    "TensorFlow には、tf.keras パッケージにKeras APIのすべてが含まれています。Keras のレイヤーは、独自のモデルを構築する際に大変便利です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.layers パッケージの中では、レイヤーはオブジェクトです。\n",
    "# レイヤーを構築するためにすることは、単にオブジェクトを作成するだけです。\n",
    "# ほとんどのレイヤーでは、最初の引数が出力の次元あるいはチャネル数を表します。\n",
    "#Denseは全結合層\n",
    "layer = tf.keras.layers.Dense(100)\n",
    "\n",
    "# 入力の次元数は多くの場合不要となっています。それは、レイヤーが最初に使われる際に\n",
    "# 推定可能だからです。ただし、引数として渡すことで手動で指定することも可能です。\n",
    "# これは複雑なモデルを構築する場合に役に立つでしょう。\n",
    "layer = tf.keras.layers.Dense(10, input_shape=(None, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "既存のレイヤーのすべての一覧は、ドキュメントを参照してください。Dense（全結合レイヤー）、Conv2D、LSTM、BatchNormalization、Dropoutなどのたくさんのレイヤーが含まれています。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kei\\anaconda3\\envs\\py_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/BiasAdd:0' shape=(10, 10) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# レイヤーを使うには、単純にcallします。\n",
    "layer(tf.zeros([10, 5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# レイヤーにはたくさんの便利なメソッドがあります。例えば、`layer.variables`を使って\n",
    "# レイヤーのすべての変数を調べることができます。訓練可能な変数は、 `layer.trainable_variables`\n",
    "# でわかります。この例では、全結合レイヤーには重みとバイアスの変数があります。\n",
    "layer.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'dense_1/kernel:0' shape=(5, 10) dtype=float32>,\n",
       " <tf.Variable 'dense_1/bias:0' shape=(10,) dtype=float32>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# これらの変数には便利なアクセサを使ってアクセス可能です。\n",
    "layer.kernel, layer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### カスタムレイヤーの実装\n",
    "独自のレイヤーを実装する最良の方法は、tf.keras.Layer クラスを拡張し、下記のメソッドを実装することです。\n",
    "\n",
    "- __init__ , 入力に依存しないすべての初期化を行う\n",
    "- build, 入力の shape を知った上で、残りの初期化を行う\n",
    "- call, フォワード計算を行う\n",
    "\n",
    "build が呼ばれるまで変数の生成を待つ必要はなく、__init__ で作成できることに注意してください。しかしながら、build で変数を生成することの優位な点は、レイヤーがオペレーションをしようとする入力の shape に基づいて、後から定義できる点です。これに対して、__init__ で変数を生成するということは、そのために必要な shape を明示的に指定する必要があるということです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-f83c71940909>:14: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "Tensor(\"my_dense_layer/MatMul:0\", shape=(10, 10), dtype=float32)\n",
      "[<tf.Variable 'my_dense_layer/kernel:0' shape=(5, 10) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "#tf.keras.layers.Layerを継承, サブクラス化してモデルを定義\n",
    "class MyDenseLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_outputs):\n",
    "        #Python2の書き方\n",
    "        #親クラスの初期化を行う\n",
    "        super(MyDenseLayer, self).__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "    \n",
    "    #重みを定義\n",
    "    #self.kernelをadd_variableで上書き\n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_variable(\"kernel\", \n",
    "                                        shape=[int(input_shape[-1]), \n",
    "                                               self.num_outputs])\n",
    "    #フォワード計算を行う\n",
    "    #tf.matmulは内積\n",
    "    def call(self, input):\n",
    "        return tf.matmul(input, self.kernel)\n",
    "\n",
    "#引数は出力の次元あるいはチャネル数\n",
    "layer = MyDenseLayer(10)\n",
    "print(layer(tf.zeros([10, 5])))\n",
    "#trainable_variablesで訓練可能な変数を見ている\n",
    "print(layer.trainable_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "できるだけ標準のレイヤーを使ったほうが、概してコードは読みやすく保守しやすくなります。コードを読む人は標準的なレイヤーの振る舞いに慣れているからです。tf.keras.layers にはないレイヤーを使いたい場合には、githubのイシューを登録するか、もっとよいのはプルリクエストを送ることです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデル：レイヤーの組み合わせ\n",
    "機械学習では、多くのレイヤーに類するものが、既存のレイヤーを組み合わせることで実装されています。例えば、[ResNet](https://deepage.net/deep_learning/2016/11/30/resnet.html)の残差ブロックは、畳込み、バッチ正規化とショートカットの組み合わせです。\n",
    "\n",
    "他のレイヤーからなるレイヤーに類するものを定義する際の主役は、tf.keras.Model クラスです。このクラスを継承することで実装できます。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://deepage.net/img/resnet/residual_block.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://deepage.net/img/resnet/residual_block.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"resnet_identity_block/Relu_2:0\", shape=(1, 2, 3, 3), dtype=float32)\n",
      "['resnet_identity_block/conv2d/kernel:0', 'resnet_identity_block/conv2d/bias:0', 'resnet_identity_block/batch_normalization/gamma:0', 'resnet_identity_block/batch_normalization/beta:0', 'resnet_identity_block/conv2d_1/kernel:0', 'resnet_identity_block/conv2d_1/bias:0', 'resnet_identity_block/batch_normalization_1/gamma:0', 'resnet_identity_block/batch_normalization_1/beta:0', 'resnet_identity_block/conv2d_2/kernel:0', 'resnet_identity_block/conv2d_2/bias:0', 'resnet_identity_block/batch_normalization_2/gamma:0', 'resnet_identity_block/batch_normalization_2/beta:0']\n"
     ]
    }
   ],
   "source": [
    "#tf.keras.Modelを継承,サブクラス化してモデルを定義\n",
    "class ResnetIdentityBlock(tf.keras.Model):\n",
    "    #親クラスの初期化を行う\n",
    "    def __init__(self, kernel_size, filters):\n",
    "        super(ResnetIdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "        \n",
    "        #Conv2Dは2次元の畳み込みレイヤー\n",
    "        #filters1は整数で出力空間の次元(畳み込みの出力フィルタの数)\n",
    "        #(1, 1)は2次元の畳み込みウィンドウの幅と高さ\n",
    "        self.conv2a = tf.keras.layers.Conv2D(filters1, (1, 1))\n",
    "        #BatchNormalizationは各バッチ毎に前の出力を正規化する(平均0標準偏差1)\n",
    "        self.bn2a = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        #引数のkernel_sizeを第2引数にとる\n",
    "        self.conv2b = tf.keras.layers.Conv2D(filters2, kernel_size, padding='same')\n",
    "        self.bn2b = tf.keras.layers.BatchNormalization()\n",
    "        \n",
    "        self.conv2c = tf.keras.layers.Conv2D(filters3, (1, 1))\n",
    "        self.bn2c = tf.keras.layers.BatchNormalization()\n",
    "    \n",
    "    #フォワードパスを定義\n",
    "    def call(self, input_tensor, training=False):\n",
    "        #入力は(batch_size, steps, input_dim)の3階テンソル\n",
    "        #出力は(batch_size, new_steps, nb_filterの3階テンソル\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        #活性化関数はReLU関数\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "        \n",
    "        #残差ブロックは畳み込み層とshortcut connectionの組み合わせ\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "    \n",
    "block = ResnetIdentityBlock(1, [1, 2, 3])\n",
    "print(block(tf.zeros([1, 2, 3, 3])))\n",
    "print([x.name for x in block.trainable_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "しかし、ほとんどの場合には、モデルはレイヤーを次々に呼び出すことで構成されます。tf.keras.Sequential クラスを使うことで、これをかなり短いコードで実装できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'sequential/batch_normalization_5/cond/Merge:0' shape=(1, 2, 3, 3) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_seq = tf.keras.Sequential([tf.keras.layers.Conv2D(1, (1, 1), \n",
    "                                                    input_shape=(\n",
    "                                                        None, None, 3)),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(2, 1,\n",
    "                                                    padding='same'),\n",
    "                             tf.keras.layers.BatchNormalization(),\n",
    "                             tf.keras.layers.Conv2D(3, (1, 1)),\n",
    "                             tf.keras.layers.BatchNormalization()])\n",
    "my_seq(tf.zeros([1, 2, 3, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題2】（アドバンス課題）様々な手法を実行\n",
    "TensorFLowやGoogle AI ResearchのGitHubリポジトリには、定番のモデルから最新のモデルまで多様なコードが公開されています。これらから興味あるものを選び実行してください。\n",
    "\n",
    "\n",
    "なお、これらのコードは初学者向けではないため、巨大なデータセットのダウンロードが必要な場合など、実行が簡単ではないこともあります。そういった場合は、コードリーディングを行ってください。\n",
    "\n",
    "\n",
    "models/research at master · tensorflow/models\n",
    "\n",
    "\n",
    "google-research/google-research: Google AI Research\n",
    "\n",
    "\n",
    "更新日が古いものはPythonやTensorFlowのバージョンが古く、扱いずらい場合があります。新しいものから見ることを推奨します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 異なるフレームワークへの書き換え\n",
    "\n",
    "「ディープラーニングフレームワーク1」で作成した4種類のデータセットを扱うTensorFLowのコードを異なるフレームワークに変更していきます。\n",
    "\n",
    "\n",
    "- Iris（Iris-versicolorとIris-virginicaのみの2値分類）\n",
    "- Iris（3種類全ての目的変数を使用して多値分類）\n",
    "- House Prices\n",
    "- MNIST\n",
    "\n",
    "## Kerasへの書き換え\n",
    "KerasはTensorFLowに含まれるtf.kerasモジュールを使用してください。\n",
    "\n",
    "\n",
    "KerasにはSequentialモデルかFunctional APIかなど書き方に種類がありますが、これは指定しません。\n",
    "\n",
    "\n",
    "## 【問題3】Iris（2値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する2値分類をKerasに書き換えてください。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TensorFlowで実装したニューラルネットワークを使いIrisデータセットを2値分類する\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "# データフレームから条件抽出\n",
    "df = df[(df[\"Species\"] == \"Iris-versicolor\")|(df[\"Species\"] == \"Iris-virginica\")]\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "# ラベルを数値に変換\n",
    "y[y=='Iris-versicolor'] = 0\n",
    "y[y=='Iris-virginica'] = 1\n",
    "y = y.astype(np.int)[:, np.newaxis]\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras Sequential model API\n",
    "1. Sequential()のインスタンスを作成し、レイヤをスタックする\n",
    "2. Sequential()のインスタンスをcompileする\n",
    "3. インスタンスにfitし、評価、predictする\n",
    "4. インスタンスをsave\n",
    "\n",
    "以下、Keras Sequential model APIの記法で、Sequential()のインスタンスを作成し、addメソッドでレイヤのインスタンスをスタックする書き方"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kei\\anaconda3\\envs\\py_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "#モデルを初期化\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#1つ目の隠れ層を追加\n",
    "#10個の隠れユニットで構成\n",
    "#入力層のためimput_dimの属性の値はデータセットの特徴量列の個数\n",
    "model.add(keras.layers.Dense(10, input_dim=X_train.shape[1]))\n",
    "#活性化関数はReLU\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "#2つ目の隠れ層を追加\n",
    "#連続する層のunitsとinput_dimの個数を一致させる\n",
    "model.add(keras.layers.Dense(y_train.shape[1], input_dim=10))\n",
    "#活性化関数はsigmoid\n",
    "model.add(keras.layers.Activation('sigmoid')) \n",
    "\n",
    "#オプティマイザとコスト関数を指定してモデルをコンパイル\n",
    "#binary_crossentropyはlog loss(2値分類の評価指標, クロスエントロピー)\n",
    "#正解ラベルと予測値との距離を考慮した評価値\n",
    "model.compile(optimizer='SGD',loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kei\\anaconda3\\envs\\py_env\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kei\\anaconda3\\envs\\py_env\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/20\n",
      "64/64 [==============================] - 0s 4ms/step - loss: 0.9717\n",
      "Epoch 2/20\n",
      "64/64 [==============================] - 0s 254us/step - loss: 0.7825\n",
      "Epoch 3/20\n",
      "64/64 [==============================] - 0s 280us/step - loss: 0.7749\n",
      "Epoch 4/20\n",
      "64/64 [==============================] - 0s 180us/step - loss: 0.7701\n",
      "Epoch 5/20\n",
      "64/64 [==============================] - 0s 325us/step - loss: 0.7573\n",
      "Epoch 6/20\n",
      "64/64 [==============================] - 0s 369us/step - loss: 0.7499\n",
      "Epoch 7/20\n",
      "64/64 [==============================] - 0s 249us/step - loss: 0.7421\n",
      "Epoch 8/20\n",
      "64/64 [==============================] - 0s 296us/step - loss: 0.7470\n",
      "Epoch 9/20\n",
      "64/64 [==============================] - 0s 327us/step - loss: 0.7417\n",
      "Epoch 10/20\n",
      "64/64 [==============================] - 0s 280us/step - loss: 0.7404\n",
      "Epoch 11/20\n",
      "64/64 [==============================] - 0s 405us/step - loss: 0.7415\n",
      "Epoch 12/20\n",
      "64/64 [==============================] - 0s 375us/step - loss: 0.7384\n",
      "Epoch 13/20\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.7160\n",
      "Epoch 14/20\n",
      "64/64 [==============================] - 0s 321us/step - loss: 0.7274\n",
      "Epoch 15/20\n",
      "64/64 [==============================] - 0s 358us/step - loss: 0.7056\n",
      "Epoch 16/20\n",
      "64/64 [==============================] - 0s 343us/step - loss: 0.7061\n",
      "Epoch 17/20\n",
      "64/64 [==============================] - 0s 434us/step - loss: 0.7120\n",
      "Epoch 18/20\n",
      "64/64 [==============================] - 0s 469us/step - loss: 0.7104\n",
      "Epoch 19/20\n",
      "64/64 [==============================] - 0s 376us/step - loss: 0.7002\n",
      "Epoch 20/20\n",
      "64/64 [==============================] - 0s 464us/step - loss: 0.7050\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x20873126948>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitメソッドを呼び出してモデルのトレーニングを行う\n",
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.53\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train)\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)\n",
    "train_acc = correct_preds / y_train.shape[0]\n",
    "print(\"Training Accuracy = {:.2f}\".format(np.mean(train_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy = 0.38\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model.predict_classes(X_val)\n",
    "correct_preds = np.sum(y_val == y_val_pred, axis=0)\n",
    "val_acc = correct_preds / y_val.shape[0]\n",
    "print(\"Val Accuracy = {:.2f}\".format(np.mean(val_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.50\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test)\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)\n",
    "test_acc = correct_preds / y_test.shape[0]\n",
    "print(\"Test Accuracy = {:.2f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題4】Iris（多値分類）をKerasで学習\n",
    "TensorFlowによるIrisデータセットに対する3値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"Iris.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "y = df[\"Species\"]\n",
    "X = df.loc[:, [\"SepalLengthCm\", \"SepalWidthCm\", \"PetalLengthCm\", \"PetalWidthCm\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "# ワンホットライブラリのインスタンス作成\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y = enc.fit_transform(y[:, np.newaxis])\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#レイヤの通し番号をリセット\n",
    "K.clear_session()\n",
    "\n",
    "#モデルを初期化\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#1つ目の隠れ層を追加\n",
    "#12個の隠れユニットで構成\n",
    "#入力層のためimput_dimの属性の値はデータセットの特徴量列の個数\n",
    "model.add(keras.layers.Dense(10, input_dim=X_train.shape[1]))\n",
    "#活性化関数はReLU\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "#連続する層のunitsとinput_dimの個数を一致させる\n",
    "model.add(keras.layers.Dense(y_train.shape[1], input_dim=10))\n",
    "#活性化関数はSoftmax\n",
    "model.add(keras.layers.Activation('softmax')) \n",
    "\n",
    "#オプティマイザとコスト関数を指定してモデルをコンパイル\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kei\\anaconda3\\envs\\py_env\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "96/96 [==============================] - 0s 1ms/step - loss: 0.9484\n",
      "Epoch 2/20\n",
      "96/96 [==============================] - 0s 424us/step - loss: 0.7245\n",
      "Epoch 3/20\n",
      "96/96 [==============================] - 0s 283us/step - loss: 0.6696\n",
      "Epoch 4/20\n",
      "96/96 [==============================] - 0s 236us/step - loss: 0.6179\n",
      "Epoch 5/20\n",
      "96/96 [==============================] - 0s 284us/step - loss: 0.5831\n",
      "Epoch 6/20\n",
      "96/96 [==============================] - 0s 282us/step - loss: 0.5492\n",
      "Epoch 7/20\n",
      "96/96 [==============================] - 0s 308us/step - loss: 0.5266\n",
      "Epoch 8/20\n",
      "96/96 [==============================] - 0s 308us/step - loss: 0.5028\n",
      "Epoch 9/20\n",
      "96/96 [==============================] - 0s 329us/step - loss: 0.4896\n",
      "Epoch 10/20\n",
      "96/96 [==============================] - 0s 371us/step - loss: 0.4735\n",
      "Epoch 11/20\n",
      "96/96 [==============================] - 0s 333us/step - loss: 0.4552\n",
      "Epoch 12/20\n",
      "96/96 [==============================] - 0s 308us/step - loss: 0.4382\n",
      "Epoch 13/20\n",
      "96/96 [==============================] - 0s 240us/step - loss: 0.4256\n",
      "Epoch 14/20\n",
      "96/96 [==============================] - 0s 264us/step - loss: 0.4194\n",
      "Epoch 15/20\n",
      "96/96 [==============================] - 0s 215us/step - loss: 0.4048\n",
      "Epoch 16/20\n",
      "96/96 [==============================] - 0s 350us/step - loss: 0.4044\n",
      "Epoch 17/20\n",
      "96/96 [==============================] - 0s 290us/step - loss: 0.3688\n",
      "Epoch 18/20\n",
      "96/96 [==============================] - 0s 333us/step - loss: 0.3733\n",
      "Epoch 19/20\n",
      "96/96 [==============================] - 0s 283us/step - loss: 0.3674\n",
      "Epoch 20/20\n",
      "96/96 [==============================] - 0s 220us/step - loss: 0.3629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x208741d7f48>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitメソッドを呼び出してモデルのトレーニングを行う\n",
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデル評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.98\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = model.predict_classes(X_train)\n",
    "y_train_pred = enc.fit_transform(y_train_pred[:, np.newaxis])\n",
    "correct_preds = np.sum(y_train == y_train_pred, axis=0)\n",
    "train_acc = correct_preds / y_train.shape[0]\n",
    "print(\"Training Accuracy = {:.2f}\".format(np.mean(train_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Accuracy = 0.94\n"
     ]
    }
   ],
   "source": [
    "y_val_pred = model.predict_classes(X_val)\n",
    "y_val_pred = enc.fit_transform(y_val_pred[:, np.newaxis])\n",
    "correct_preds = np.sum(y_val == y_val_pred, axis=0)\n",
    "val_acc = correct_preds / y_val.shape[0]\n",
    "print(\"Val Accuracy = {:.2f}\".format(np.mean(val_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 1.00\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = model.predict_classes(X_test)\n",
    "y_test_pred = enc.fit_transform(y_test_pred[:, np.newaxis])\n",
    "correct_preds = np.sum(y_test == y_test_pred, axis=0)\n",
    "test_acc = correct_preds / y_test.shape[0]\n",
    "print(\"Test Accuracy = {:.2f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題5】House PricesをKerasで学習\n",
    "TensorFlowによるHouse Pricesデータセットに対する回帰をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460,)\n",
      "(1460, 1)\n"
     ]
    }
   ],
   "source": [
    "# データセットの読み込み\n",
    "dataset_path =\"train.csv\"\n",
    "df = pd.read_csv(dataset_path)\n",
    "\n",
    "y = df[\"SalePrice\"]\n",
    "X = df.loc[:, [\"GrLivArea\", \"YearBuilt\"]]\n",
    "y = np.array(y)\n",
    "X = np.array(X)\n",
    "\n",
    "print(y.shape)\n",
    "y = y[:, np.newaxis]\n",
    "print(y.shape)\n",
    "\n",
    "# trainとtestに分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# さらにtrainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "\n",
    "#モデルを初期化\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#1つ目の隠れ層を追加\n",
    "#12個の隠れユニットで構成\n",
    "#入力層のためimput_dimの属性の値はデータセットの特徴量列の個数\n",
    "model.add(keras.layers.Dense(5, input_dim=X_train.shape[1]))\n",
    "#活性化関数はReLU\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "#連続する層のunitsとinput_dimの個数を一致させる\n",
    "model.add(keras.layers.Dense(y_train.shape[1], input_dim=5))\n",
    "# model.add(keras.layers.Activation('softmax')) \n",
    "\n",
    "#オプティマイザとコスト関数を指定してモデルをコンパイル\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kei\\anaconda3\\envs\\py_env\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "934/934 [==============================] - 0s 422us/step - loss: 39352886568.0171\n",
      "Epoch 2/20\n",
      "934/934 [==============================] - 0s 247us/step - loss: 39352623850.6210\n",
      "Epoch 3/20\n",
      "934/934 [==============================] - 0s 237us/step - loss: 39352233730.7409\n",
      "Epoch 4/20\n",
      "934/934 [==============================] - 0s 237us/step - loss: 39351700416.4111\n",
      "Epoch 5/20\n",
      "934/934 [==============================] - 0s 308us/step - loss: 39351020422.3041\n",
      "Epoch 6/20\n",
      "934/934 [==============================] - 0s 282us/step - loss: 39350190778.3812\n",
      "Epoch 7/20\n",
      "934/934 [==============================] - 0s 257us/step - loss: 39349215889.8158\n",
      "Epoch 8/20\n",
      "934/934 [==============================] - 0s 320us/step - loss: 39348093968.4454\n",
      "Epoch 9/20\n",
      "934/934 [==============================] - 0s 266us/step - loss: 39346819478.7495\n",
      "Epoch 10/20\n",
      "934/934 [==============================] - 0s 287us/step - loss: 39345355681.7131\n",
      "Epoch 11/20\n",
      "934/934 [==============================] - 0s 314us/step - loss: 39343598351.8972\n",
      "Epoch 12/20\n",
      "934/934 [==============================] - 0s 234us/step - loss: 39341637801.9358\n",
      "Epoch 13/20\n",
      "934/934 [==============================] - 0s 262us/step - loss: 39339495929.4218\n",
      "Epoch 14/20\n",
      "934/934 [==============================] - 0s 300us/step - loss: 39337128746.2098\n",
      "Epoch 15/20\n",
      "934/934 [==============================] - 0s 261us/step - loss: 39334459201.2334\n",
      "Epoch 16/20\n",
      "934/934 [==============================] - 0s 230us/step - loss: 39331524409.5589\n",
      "Epoch 17/20\n",
      "934/934 [==============================] - 0s 250us/step - loss: 39328386743.0921\n",
      "Epoch 18/20\n",
      "934/934 [==============================] - 0s 331us/step - loss: 39325071080.4283\n",
      "Epoch 19/20\n",
      "934/934 [==============================] - 0s 292us/step - loss: 39321588826.9979\n",
      "Epoch 20/20\n",
      "934/934 [==============================] - 0s 230us/step - loss: 39317948522.3469\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2087528fd08>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitメソッドを呼び出してモデルのトレーニングを行う\n",
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 【問題6】MNISTをKerasで学習\n",
    "TensorFlowによるMNISTデータセットによる画像の多値分類をKerasに書き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# 平坦化\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "# 前処理\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "\n",
    "#正規化\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# ワンホットライブラリのインスタンス作成\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test = enc.fit_transform(y_test[:, np.newaxis])\n",
    "\n",
    "# trainとvalに分割\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "K.clear_session()\n",
    "\n",
    "#モデルを初期化\n",
    "model = keras.models.Sequential()\n",
    "#1つ目の隠れ層を追加\n",
    "#12個の隠れユニットで構成\n",
    "#入力層のためimput_dimの属性の値はデータセットの特徴量列の個数\n",
    "model.add(keras.layers.Dense(15, input_dim=X_train.shape[1]))\n",
    "#活性化関数はReLU\n",
    "model.add(keras.layers.Activation('relu'))\n",
    "\n",
    "#連続する層のunitsとinput_dimの個数を一致させる\n",
    "model.add(keras.layers.Dense(y_train.shape[1], input_dim=12))\n",
    "#活性化関数はSoftmax\n",
    "model.add(keras.layers.Activation('softmax')) \n",
    "\n",
    "#オプティマイザとコスト関数を指定してモデルをコンパイル\n",
    "model.compile(optimizer='SGD',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kei\\anaconda3\\envs\\py_env\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 18s 375us/step - loss: 0.4502 - accuracy: 0.8717\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 19s 394us/step - loss: 0.2800 - accuracy: 0.9195\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 24s 496us/step - loss: 0.2397 - accuracy: 0.9306\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 24s 507us/step - loss: 0.2155 - accuracy: 0.9381\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 24s 501us/step - loss: 0.1984 - accuracy: 0.9426\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 19s 399us/step - loss: 0.1863 - accuracy: 0.9455\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 18s 377us/step - loss: 0.1767 - accuracy: 0.9489\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 16s 338us/step - loss: 0.1690 - accuracy: 0.9499\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 17s 346us/step - loss: 0.1627 - accuracy: 0.9520\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 22s 451us/step - loss: 0.1576 - accuracy: 0.9529\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 28s 573us/step - loss: 0.1536 - accuracy: 0.9546\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 28s 578us/step - loss: 0.1497 - accuracy: 0.9557\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 21s 440us/step - loss: 0.1461 - accuracy: 0.9564\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 20s 414us/step - loss: 0.1431 - accuracy: 0.9569\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 21s 447us/step - loss: 0.1408 - accuracy: 0.9581\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 20s 426us/step - loss: 0.1385 - accuracy: 0.9595\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 22s 463us/step - loss: 0.1361 - accuracy: 0.9604\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 22s 466us/step - loss: 0.1334 - accuracy: 0.9600\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 21s 437us/step - loss: 0.1314 - accuracy: 0.9609\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 26s 541us/step - loss: 0.1300 - accuracy: 0.9603\n",
      "Accuracy = 0.95\n"
     ]
    }
   ],
   "source": [
    "#fitメソッドを呼び出してモデルのトレーニングを行う\n",
    "model.fit(X_train, y_train, nb_epoch=20, batch_size=5)\n",
    "\n",
    "# モデル評価\n",
    "loss, accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "print(\"Accuracy = {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
