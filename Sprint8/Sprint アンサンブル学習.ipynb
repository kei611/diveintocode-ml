{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# アンサンブル学習\n",
    "\n",
    "3種類のアンサンブル学習をスクラッチ実装していきます。そして、それぞれの効果を小さめのデータセットで確認します。\n",
    "\n",
    "\n",
    "ブレンディング\n",
    "バギング\n",
    "スタッキング\n",
    "\n",
    "## 小さなデータセットの用意\n",
    "以前も利用した回帰のデータセットを用意します。\n",
    "\n",
    "\n",
    "House Prices: Advanced Regression Techniques\n",
    "\n",
    "\n",
    "この中のtrain.csvをダウンロードし、目的変数としてSalePrice、説明変数として、GrLivAreaとYearBuiltを使います。\n",
    "\n",
    "\n",
    "train.csvを学習用（train）8割、検証用（val）2割に分割してください。\n",
    "\n",
    "\n",
    "## scikit-learn\n",
    "単一のモデルはスクラッチ実装ではなく、scikit-learnなどのライブラリの使用を推奨します。\n",
    "\n",
    "\n",
    "sklearn.linear_model.LinearRegression — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "sklearn.svm.SVR — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "sklearn.tree.DecisionTreeRegressor — scikit-learn 0.21.3 documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.loc[:, 'SalePrice']\n",
    "X = data.loc[:, ['GrLivArea', 'YearBuilt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.values\n",
    "X = X.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ブレンディング\n",
    "\n",
    "## 【問題1】ブレンディングのスクラッチ実装\n",
    "ブレンディング をスクラッチ実装し、単一モデルより精度があがる例を 最低3つ 示してください。精度があがるとは、検証用データに対する平均二乗誤差（MSE）が小さくなることを指します。\n",
    "\n",
    "\n",
    "## ブレンディングとは\n",
    "ブレンディングとは、N個の多様なモデルを独立して学習させ、推定結果を重み付けした上で足し合わせる方法です。最も単純には平均をとります。多様なモデルとは、以下のような条件を変化させることで作り出すものです。\n",
    "\n",
    "\n",
    "- 手法（例：線形回帰、SVM、決定木、ニューラルネットワークなど）\n",
    "- ハイパーパラメータ（例：SVMのカーネルの種類、重みの初期値など）\n",
    "- 入力データの前処理の仕方（例：標準化、対数変換、PCAなど）\n",
    "\n",
    "重要なのはそれぞれのモデルが大きく異なることです。\n",
    "\n",
    "\n",
    "回帰問題でのブレンディングは非常に単純であるため、scikit-learnには用意されていません。\n",
    "\n",
    "\n",
    "《補足》\n",
    "分類問題の場合は、多数決を行います。回帰問題に比べると複雑なため、scikit-learnにはVotingClassifierが用意されています。\n",
    "\n",
    "sklearn.ensemble.VotingClassifier — scikit-learn 0.21.3 documentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Blending():\n",
    "    def __init__(self, models, weights=None):\n",
    "        self.models = models\n",
    "        self.weights = weights\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = []\n",
    "        for mdl in self.models:\n",
    "            fitted_mdl = mdl.fit(X, y)\n",
    "            self.models_.append(fitted_mdl)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = np.asarray([mdl.predict(X) for mdl in self.models_])\n",
    "        avg_pred = np.average(pred, axis=0, weights=self.weights)\n",
    "        return avg_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上から順に\n",
    "- ロジスティック回帰\n",
    "- 決定木\n",
    "- SVM  \n",
    "で分類した際の平均二乗誤差（MSE）の値を算出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2016350238.211333\n",
      "2590490870.1061645\n",
      "4980345342.777397\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "clf1 = LinearRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = SVC()\n",
    "\n",
    "for clf in [clf1, clf2, clf3]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数の分類器をブレンディングさせる。   \n",
    "分類器(重み)\n",
    "- ロジスティック回帰(0.6)\n",
    "- 決定木(0.2)\n",
    "- SVM(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1874264303.6311107\n"
     ]
    }
   ],
   "source": [
    "mv_clf = Blending(models=[clf1, clf2, clf3], weights=[0.6, 0.2, 0.2])\n",
    "mv_clf.fit(X_train, y_train)\n",
    "y_pred_mv = mv_clf.predict(X_test)\n",
    "score = mean_squared_error(y_true=y_test, y_pred=y_pred_mv)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ロジスティック回帰(0.7)\n",
    "- 決定木(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1817367571.462801\n"
     ]
    }
   ],
   "source": [
    "mv_clf2 = Blending(models=[clf1, clf2], weights=[0.7, 0.3])\n",
    "mv_clf2.fit(X_train, y_train)\n",
    "y_pred_mv2 = mv_clf2.predict(X_test)\n",
    "score2 = mean_squared_error(y_true=y_test, y_pred=y_pred_mv2)\n",
    "print(score2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ロジスティック回帰(0.9)\n",
    "- SVM(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2042899084.3169372\n"
     ]
    }
   ],
   "source": [
    "mv_clf3 = Blending(models=[clf1, clf3], weights=[0.9, 0.1])\n",
    "mv_clf3.fit(X_train, y_train)\n",
    "y_pred_mv3 = mv_clf3.predict(X_test)\n",
    "score3 = mean_squared_error(y_true=y_test, y_pred=y_pred_mv3)\n",
    "print(score3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰の重みをかなり大きくしたが、ロジスティック回帰単体よりMSEは少し大きくなった。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# バギング\n",
    "\n",
    "## 【問題2】バギングのスクラッチ実装\n",
    "バギング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "\n",
    "## バギングとは\n",
    "バギングは入力データの選び方を多様化する方法です。学習データから重複を許した上でランダムに抜き出すことで、N種類のサブセット（ ブートストラップサンプル ）を作り出します。それらによってモデルをN個学習し、推定結果の平均をとります。ブレンディングと異なり、それぞれの重み付けを変えることはありません。\n",
    "\n",
    "\n",
    "sklearn.model_selection.train_test_split — scikit-learn 0.21.3 documentation\n",
    "\n",
    "\n",
    "scikit-learnのtrain_test_splitを、shuffleパラメータをTrueにして使うことで、ランダムにデータを分割することができます。これによりブートストラップサンプルが手に入ります。\n",
    "\n",
    "\n",
    "推定結果の平均をとる部分はブースティングと同様の実装になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bagging():\n",
    "    def __init__(self, base_estimator, n_estimators):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.n_estimators = n_estimators\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_ = []\n",
    "        #X_slct, _, y_slct, _ = train_test_split(X, y, shuffle=True)\n",
    "        random_index = np.random.choice(np.arange(X.shape[0]), size=X.shape[0])\n",
    "        X_slct = X[random_index]\n",
    "        y_slct = y[random_index]\n",
    "        for i in range(self.n_estimators):\n",
    "            fitted_mdl = self.base_estimator.fit(X_slct, y_slct)\n",
    "            self.models_.append(fitted_mdl)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        pred = np.asarray([mdl.predict(X) for mdl in self.models_])\n",
    "        avg_pred = np.average(pred, axis=0)\n",
    "        return avg_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "決定木のバギング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2291112180.8630137\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "bg = Bagging(base_estimator=tree, n_estimators=10)\n",
    "bg.fit(X_train, y_train)\n",
    "y_pred_bg = bg.predict(X_test)\n",
    "score = mean_squared_error(y_true=y_test, y_pred=y_pred_bg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2235680785.712329\n"
     ]
    }
   ],
   "source": [
    "bg = Bagging(base_estimator=tree, n_estimators=30)\n",
    "bg.fit(X_train, y_train)\n",
    "y_pred_bg = bg.predict(X_test)\n",
    "score = mean_squared_error(y_true=y_test, y_pred=y_pred_bg)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSEが下がっていることが分かる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# スタッキング\n",
    "\n",
    "## 【問題3】スタッキングのスクラッチ実装\n",
    "スタッキング をスクラッチ実装し、単一モデルより精度があがる例を 最低1つ 示してください。\n",
    "\n",
    "\n",
    "## スタッキングとは\n",
    "スタッキングの手順は以下の通りです。最低限ステージ0とステージ1があればスタッキングは成立するため、それを実装してください。まずはK0=3,M0=2程度にします。\n",
    "\n",
    "#### 《学習時》\n",
    "\n",
    "\n",
    "（ステージ0）\n",
    "\n",
    "\n",
    "- 学習データをK0個に分割する。\n",
    "- 分割した内の(K0−1)個をまとめて学習用データ、残り1個を推定用データとする組み合わせがK0個作れる。\n",
    "- あるモデルのインスタンスをK0個用意し、異なる学習用データを使い学習する。\n",
    "- それぞれの学習済みモデルに対して、使っていない残り1個の推定用データを入力し、推定値を得る。（これをブレンドデータと呼ぶ）\n",
    "- さらに、異なるモデルのインスタンスもK0個用意し、同様のことを行う。モデルがM0個あれば、M0個のブレンドデータが得られる。\n",
    "\n",
    "（ステージn）\n",
    "- ステージn−1のブレンドデータをMn−1次元の特徴量を持つ学習用データと考え、Kn個に分割する。以下同様である。\n",
    "\n",
    "（ステージN）＊最後のステージ\n",
    "\n",
    "- ステージN−1のMN−1個のブレンドデータをMN−1次元の特徴量の入力として、1種類のモデルの学習を行う。これが最終的な推定を行うモデルとなる。\n",
    "\n",
    "#### 《推定時》\n",
    "\n",
    "\n",
    "（ステージ0）\n",
    "\n",
    "- テストデータをK0×M0個の学習済みモデルに入力し、K0×M0個の推定値を得る。これをK0の軸で平均値を求め M0次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージn）\n",
    "\n",
    "- ステージn−1で得たブレンドテストをKn×Mn個の学習済みモデルに入力し、Kn×Mn個の推定値を得る。これをKnの軸で平均値を求めM0次元の特徴量を持つデータを得る。（ブレンドテストと呼ぶ）\n",
    "\n",
    "（ステージN）＊最後のステージ\n",
    "\n",
    "\n",
    "- ステージN−1で得たブレンドテストを学習済みモデルに入力し、推定値を得る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "lab_enc = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacking():\n",
    "    def __init__(self, models, meta_model, k0, n_stage):\n",
    "        self.models = models\n",
    "        self.meta_model = meta_model\n",
    "        self.k0 = k0\n",
    "        self.n_stage = n_stage\n",
    "        \n",
    "    def train(self, X, y):\n",
    "\n",
    "        self.models_ = []\n",
    "\n",
    "        kf = KFold(n_splits=k0)\n",
    "        blend_data = np.empty((int(len(X)*1/self.k0), 0))\n",
    "\n",
    "        for mdl in models: \n",
    "            blend_data_val = np.empty((int(len(X)*1/self.k0), ))\n",
    "\n",
    "            for train_idx, test_idx in kf.split(X, y):\n",
    "                fitted_mdl = mdl.fit(X[train_idx], y[train_idx])\n",
    "                models_.append(fitted_mdl)\n",
    "\n",
    "                blend_data_val += fitted_mdl.predict(X[test_idx])\n",
    "\n",
    "            blend_data = np.append(blend_data, (blend_data_val / self.k0)[:, np.newaxis], axis=1)\n",
    "        \n",
    "        blend_data_val = lab_enc.fit_transform(blend_data_val)\n",
    "        return blend_data, blend_data_val\n",
    "\n",
    "    def last_train(self, X, y):\n",
    "        self.meta_model.fit(X, y)\n",
    "\n",
    "        return self\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.models_set = []\n",
    "        blend_data, blend_data_val = self.train(X, y)\n",
    "        for i in range(self.n_stage):\n",
    "\n",
    "            blend_data, blend_data_val = self.train(blend_data, blend_data_val)\n",
    "            \n",
    "        self.last_train(blend_data, blend_data_val)\n",
    "        \n",
    "        return self        \n",
    "            \n",
    "    def _predict(self, X, models_set):\n",
    "        pred = np.asarray([mdl.predict(X) for mdl in models_set])\n",
    "        avg_pred = np.average(pred, axis=0)\n",
    "        return avg_pred\n",
    "        \n",
    "    def last_predict(self, X):\n",
    "        return self.meta_model.predict(X)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        blend_test_set = self._predict(X, self.models_set[0])\n",
    "        for i in range(self.n_stage):\n",
    "            blend_test_set = self._predict(X, self.models_set[i+1])\n",
    "            \n",
    "        return self.last_predict(blend_test_set)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1772803242.9021819\n",
      "2834091131.191781\n",
      "4345032720.239726\n"
     ]
    }
   ],
   "source": [
    "clf1 = LinearRegression()\n",
    "clf2 = DecisionTreeClassifier()\n",
    "clf3 = SVC()\n",
    "\n",
    "for clf in [clf1, clf2, clf3]:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    score = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "    print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ステージ数:3\n",
    "- 分類器: ロジスティック回帰, SVC, 決定木(最後のステージ)\n",
    "- データ分割数: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1399606044.9352725\n"
     ]
    }
   ],
   "source": [
    "stck = Stacking(models=[clf1, clf3], meta_model=clf2, k0=4, n_stage=1)\n",
    "stck.fit(X_train, y_train)\n",
    "y_pred = mv_clf.predict(X_test)\n",
    "score = mean_squared_error(y_true=y_test, y_pred=y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MSEは単一モデルより低くなったことが確認できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
