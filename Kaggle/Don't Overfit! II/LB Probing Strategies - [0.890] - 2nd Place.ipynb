{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [LB Probing Strategies - [0.890] - 2nd Place](https://www.kaggle.com/cdeotte/lb-probing-strategies-0-890-2nd-place)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LBプロービングテクニック-Don't Overfit! II-2位の解法\n",
    "このカーネルでは、Kaggleリーダーボード（LB）をプローブして公開テストデータセットに関する情報を取得するための効率的な戦略について説明します。 LRロジスティック回帰、SVCサポートベクトル分類、およびLDAナイーブベイズは、データを分類する線形超平面を見つける3つの方法です。 「Don't Overfit II」コンテストでは、公開テストデータセットのデータは、トレーニングデータセットの8倍です。 トレーニングデータを分類する超平面を見つける代わりに、公開テストデータセットを分類する超平面を見つけることをお勧めします。 私たちはできる。次の式を仮定しましょう。\n",
    "\n",
    "$$\n",
    "\\text{target} = \\text{Heaviside}(a_0x_0+a_1x_1+...a_{298}x_{298}+a_{299}x_{299}+\\text{noise})\n",
    "$$\n",
    "\n",
    "ヘヴィサイドステップ関数heaviside(x)は、x<0の場合は値0を、x>0の場合は値1を、x=0の場合は値1/2を返す。  \n",
    "私たちのタスクは、300の超平面係数a_kを決定することです。 a_kが独立していると仮定すると、次のコードはLBプローブを介してパブリックテストデータセットからそれらを抽出します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 33\n",
    "test = pd.read_csv('test.csv')\n",
    "sub = pd.read_csv('sample_submission.csv')\n",
    "sub['target'] = test[str(var)]\n",
    "sub.to_csv('submission'+str(var)+'.csv',index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testデータの特徴量33の列をそのまま提出ファイルの予測値として提出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://playagricola.com/Kaggle/sub33.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"http://playagricola.com/Kaggle/sub33.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a_kの値は、ちょうどLB_SCORE_Kから0.500を引いたものです。 例えば\n",
    "\n",
    "$$\n",
    "a_{33} = \\text{LB_SCORE}_{33} - 0.500 = 0.671 - 0.500 = 0.171\n",
    "$$\n",
    "変数がターゲットと負の相関がある場合（正の相関とは対照的に）、LB_SCORE_Kは0.500未満になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://playagricola.com/Kaggle/sub217.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://playagricola.com/Kaggle/sub217.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "a_{217} = \\text{LB_SCORE}_{217} - 0.500 = 0.382 - 0.500 = -0.118\n",
    "$$\n",
    "\n",
    "とても簡単です！ これを行うことにより、次の3つのトリックを追加することで、20日（100回の送信）でa_kを回復できます。\n",
    "- 最も重要な100個のa_kのみをプローブします。 abs（CV_SCORE_K-0.5）<0.04の場合、a_k = 0を設定し、プローブしません。\n",
    "- 精度を高めるには、訓練データと公開データを使用します。 LB_SCORE_Kを（8/9）* LB_SCORE_K +（1/9）* CV_SCORE_Kに置き換えます。\n",
    "- L1ペナルティを適用します。 abs（LB_SCORE_K-0.5）<0.04の場合、a_k = 0を設定します。\n",
    "\n",
    "\n",
    "これらの追加のトリックは、LBの過剰適合を防ぐのに役立ちます。 パブリックテストデータセットのみをモデル化してとオーバーフィッティングのリスクをとる代わりに、2225の合計サンプルサイズのトレーニングデータとパブリックテストデータの両方からの情報を使用します。このサンプルサイズでは、AUCが0.54以下のすべての変数が それ自体は役に立たない変数かもしれません。 したがって、abs（AUC-0.5）<0.04のすべての変数をモデルから削除します。ここで、AUC =（8/9）* LB_AUC +（1/9）* CV_AUCは、不要な変数の過剰適合を防ぎます。\n",
    "\n",
    "ここで説明するように、0.3 <AUC <0.7であるため、線形近似を使用してa_kを見つけていることに注意してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合成データセット実験¶\n",
    "この手法を合成データセットで観察してみましょう。 次に、それを実際のデータセットに適用します。 この手法を以下のモデル4に示します。 最初に、他の3つの人気モデルを紹介します。 （最初の2つのモデルはトレーニングデータのみを使用し、次の2つのモデルはパブリックテストデータを使用します）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, os\n",
    "np.random.seed(300)\n",
    "\n",
    "# GENERATE RANDOM DATA\n",
    "data = pd.DataFrame(np.zeros((20000,300)))\n",
    "for i in range(300): \n",
    "    data.iloc[:,i] = np.random.normal(0,1,20000)\n",
    "    \n",
    "# SET TARGET AS LINEAR COMBINATION OF 50 A'S PLUS NOISE \n",
    "important = 35\n",
    "noise = 3.5\n",
    "a = np.random.normal(0,1,300)\n",
    "x = np.random.choice(np.arange(300),300-important,replace=False)\n",
    "a[x] = 0\n",
    "data['target'] = data.values.dot(a) + np.random.normal(0,noise,20000)\n",
    "\n",
    "# MAKE 64% TARGET=1, 36% TARGET=0\n",
    "data.sort_values('target',inplace=True)\n",
    "data.iloc[:7200,300] = 0.0\n",
    "data.iloc[7200:,300] = 1.0\n",
    "\n",
    "# RANDOMLY SELECT TRAIN, PUBLIC, PRIVATE\n",
    "train = data.sample(250)\n",
    "public = data[ ~data.index.isin(train.index) ].sample(1975)\n",
    "private = data[ ~data.index.isin(train.index) & ~data.index.isin(public.index) ].sample(frac=1) \n",
    "\n",
    "# RESET INDICES\n",
    "train.reset_index(drop=True,inplace=True)\n",
    "public.reset_index(drop=True,inplace=True)\n",
    "private.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル1：トレーニングデータL2-Hyperplane\n",
    "トレーニングデータのみを使用し、ロジスティック回帰、L2ペナルティ、および層別k分割を使用してモデルを構築する場合、合成データセットでCV 0.772、LB 0.728およびプライベートスコア0.743を達成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Model with L2-penalty: CV = 0.77491 LB = 0.72832 Private score = 0.74249\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "oof = np.zeros(len(train))\n",
    "predsPU= np.zeros(len(public))\n",
    "predsPR= np.zeros(len(private))\n",
    "rskf = RepeatedStratifiedKFold(n_splits=25, n_repeats=5)\n",
    "for train_index, test_index in rskf.split(train.iloc[:,:-1], train['target']):\n",
    "    clf = LogisticRegression(solver='liblinear',penalty='l2',C=1.0,class_weight='balanced')\n",
    "    clf.fit(train.loc[train_index].iloc[:,:-1],train.loc[train_index]['target'])\n",
    "    oof[test_index] += clf.predict_proba(train.loc[test_index].iloc[:,:-1])[:,1]\n",
    "    predsPU += clf.predict_proba(public.iloc[:,:-1])[:,1]\n",
    "    predsPR += clf.predict_proba(private.iloc[:,:-1])[:,1]\n",
    "aucTR = round(roc_auc_score(train['target'],oof),5)\n",
    "aucPU = round(roc_auc_score(public['target'],predsPU),5)\n",
    "aucPR = round(roc_auc_score(private['target'],predsPR),5)\n",
    "print('LR Model with L2-penalty: CV =',aucTR,'LB =',aucPU,'Private score =',aucPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル2：トレーニングデータL1-Hyperplane\n",
    "トレーニングデータのみを使用し、ロジスティック回帰、L1ペナルティ、および層別kフォールドでモデルを構築する場合、合成データセットでCV 0.846、LB 0.841およびプライベートスコア0.837を達成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Model with L1-penalty: CV = 0.85657 LB = 0.84082 Private score = 0.83736\n"
     ]
    }
   ],
   "source": [
    "oof = np.zeros(len(train))\n",
    "predsPU= np.zeros(len(public))\n",
    "predsPR= np.zeros(len(private))\n",
    "rskf = RepeatedStratifiedKFold(n_splits=25, n_repeats=5)\n",
    "for train_index, test_index in rskf.split(train.iloc[:,:-1], train['target']):\n",
    "    clf = LogisticRegression(solver='liblinear',penalty='l1',C=0.1,class_weight='balanced')\n",
    "    clf.fit(train.loc[train_index].iloc[:,:-1],train.loc[train_index]['target'])\n",
    "    oof[test_index] += clf.predict_proba(train.loc[test_index].iloc[:,:-1])[:,1]\n",
    "    predsPU += clf.predict_proba(public.iloc[:,:-1])[:,1]\n",
    "    predsPR += clf.predict_proba(private.iloc[:,:-1])[:,1]\n",
    "aucTR = round(roc_auc_score(train['target'],oof),5)\n",
    "aucPU = round(roc_auc_score(public['target'],predsPU),5)\n",
    "aucPR = round(roc_auc_score(private['target'],predsPR),5)\n",
    "print('LR Model with L1-penalty: CV =',aucTR,'LB =',aucPU,'Private score =',aucPR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル3：パブリックデータL2-Hyperplane Search\n",
    "ランダムLBプロービングを使用して、プライベートスコアを増やします。 トレーニングデータモデルからの最適なL1超平面から始め、ランダムに5度回転させて再送信します。 LBスコアが増加した場合は、新しい超平面を保持します。それ以外の場合は、古い超平面を保持します。 このプロセスを30日間繰り返します（150件の提出）。\n",
    "\n",
    "このプロセスでは、ランダム検索を使用して、公開テストデータセットで最適なL2-超平面を見つけます。 トレーニングデータセットのみを使用するモデル1および2に勝っていることに注意してください。 トレーニングデータで重要であることが証明されている可変次元を介して超平面を回転させるだけで、この方法を加速できます。 （このアクセラレータは、トレーニングモデルからL1ペナルティを適用するようなものです）\n",
    "\n",
    "1か月後（150件の送信）、このメソッドは、合成データセットでLBスコア0.885およびプライベートスコア0.859を達成します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
