{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having adequate customer relations is paramount to success in any service industry. Identifying and analyzing your customer’s contentment to improve customer retention can yield many benefits. The longer a client stays with an organisation, the more value he creates. There are higher costs attached to introducing and attracting new customers. The clients also have a better understanding of the organisation and can give positive word-of-mouth promotion. (Colgate et al.,1996) Datamining is essential in this process and this practice is widely applied across industries for instance FMCG retailers (Buckinx and van den Poel, 2005), telecommunications (Mozer et al.,2000) and banking (Clemes et al., 2010) and (Xie et al., 2009).\n",
    "\n",
    "This paper focuses on Santander Bank, a large corporation focusing principally on the market in the northeast United States. Through means of a Kaggle competition (Santander, 2015), it is the objective to find an appropriate model to predict whether a client will be dissatisfied in the future based on certain characteristics. Having this model in place can ensure that Santander can take proactive steps to improve a customer’s happiness before they would take their business elsewhere.\n",
    "\n",
    "First the paper will discuss related work done on this, by now concluded, Kaggle case. Secondly it delves into the data we work with, analyzing groups of variables and individual features to give us insight in what is relevant. Thirdly several cleaning procedures that were employed to lead to better results are outlined. Fourthly we explain the performance measure of this competition and the three models: Logistic Regression, Random Forest and XGBoost that we utilize to tackle the problem. Lastly the tuning process and results are discussed. We reach an AUC score of 0.823152."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "適切な顧客関係を持つことは、あらゆるサービス業界で成功するために最も重要です。顧客維持を改善するために顧客の満足度を特定して分析すると、多くのメリットが得られます。クライアントが組織に長く滞在するほど、彼はより多くの価値を生み出します。新しい顧客の紹介と引き付けには、より高いコストがかかります。また、クライアントは組織をよりよく理解しており、積極的な口コミプロモーションを行うことができます。 （Colgate et al。、1996）データマイニングはこのプロセスに不可欠であり、この実践はFMCG小売業者（Buckinx and van den Poel、2005）、電気通信（Mozer et al。、2000）、銀行（Clemes et al）などの業界に広く適用されています。ら、2010）および（Xieら、2009）。\n",
    "\n",
    "このペーパーでは、主に米国北東部の市場に焦点を当てている大企業であるサンタンデール銀行に焦点を当てています。 Kaggle競争（Santander、2015年）を通じて、クライアントが特定の特性に基づいて将来不満を抱くかどうかを予測する適切なモデルを見つけることが目的です。このモデルを導入することで、サンタンデールが顧客の幸せを改善するための積極的な措置を講じてから、顧客が別の場所でビジネスを始めることができます。\n",
    "\n",
    "最初に、このペーパーでこれに関して行われた関連作業について説明します。次に、使用するデータを詳しく調べ、変数のグループと個々の機能を分析して、関連するものについての洞察を提供します。第三に、より良い結果につながるために採用されたいくつかの洗浄手順が概説されています。 4番目に、この競争のパフォーマンス測定と3つのモデルについて説明します。これらは、問題に取り組むために使用するロジスティック回帰、ランダムフォレスト、XGBoostです。最後に、チューニングプロセスと結果について説明します。 AUCスコアは0.823152に達しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Related Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section looks into the work of various Kaggle competitors in different sections of the leaderboard. The private leaderboard score is mentioned first after which a small description details the work done. For reference the top position had a score of: 0.829072\n",
    "\n",
    "0.828530: Silva et al. (2016) all seemingly independently do their own preprocessing, feature engineering and model selection and then combine all predictions of the models together in an ensemble using the R package optim. Preprocessing steps taken are for instance: replacing certain values by NA, dropping sparse, constant and duplicated features, normalization, log transforming features and one-hot encoding categorical features. Sophisticated feature engineering methods employed include t-Distributed Stochastic Neighbour Embedding, Principal Component Analysis and K-means. Models explored are: Follow the Proximally Regularized Leader, Regularized\n",
    "Greedy Forest, Adaboost, XGBoost, Neural Networks, Least Absolute Shrinkage and Selection Operator, Support Vector Machine, Random Forest and an Extra Trees Classifier.\n",
    "\n",
    "0.826826: Yooyen and Ma (2016) are one of the few that find and handle some duplicated observations in the train set. Furthermore they do standard preprocessing steps like removing duplicated\n",
    "and constant features, normalizing, rescaling and handling missing values. They select features based on Pearson’s Correlation Coefficient with the target and crossvalidation. Attempts at specif1\n",
    "ically handling the class imbalance and principal component analysis were fruitless. With success they added heuristic rules like var15 < 23 means the target is 0. Their main models are based on decision trees.\n",
    "\n",
    "0.8249: Wang (2016) applies hardly any preprocessing as he intends to use only decision trees that are relatively insensitive to this. He does extensively select features with the importance in the Gradient Boosting Classifier as criterion. After which he adds percentile change from feature to feature, and he applies selection again. Parameters are trained iteratively one at a time with a coarse to fine approach. Adaboost, Bagging Classifier, Extra Trees Classifier, Gradient Boosting, Random Forest and XGBoost are ensembled to lead to the final scores.\n",
    "\n",
    "0.824332: Kumar (2015) tries linear regression with the top ten features, a support vector machine in combination with principal component analysis with limited success as a start. Neural Networks, tuned Random Forest and XGBoost yield him better results. XGBoost is seen as obvious best candidate and it is used with the top N features, which makes it apparent that anything beyond 5 features only adds very minor improvements to the crossvalidation score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このセクションでは、リーダーボードのさまざまなセクションでのさまざまなKaggle競合他社の作業について説明します。プライベートリーダーボードのスコアが最初に記載され、その後に小さな説明が実行された作業の詳細を示します。参考までに、最上位のスコアは0.829072でした。\n",
    "\n",
    "0.828530：Silva et al。 （2016）すべて一見独立して、独自の前処理、機能エンジニアリング、モデル選択を行い、Rパッケージoptimを使用して、モデルのすべての予測をアンサンブルにまとめます。たとえば、特定の値をNAで置き換える、スパース、定数および複製された機能を削除する、正規化、ログ変換機能、ワンホットエンコーディングのカテゴリ機能などです。洗練された特徴エンジニアリング手法には、t-Distributed Stochastic Neighbor Embedding、主成分分析、K-meansなどがあります。探索されるモデルは次のとおりです：近接正則化リーダー、正則化に従います\n",
    "貪欲なフォレスト、Adaboost、XGBoost、ニューラルネットワーク、最小絶対収縮および選択演算子、サポートベクターマシン、ランダムフォレスト、追加のツリー分類子。\n",
    "\n",
    "0.826826：YooyenとMa（2016）は、列車セットで重複する観測を見つけて処理する数少ないものの1つです。さらに、重複を削除するなどの標準的な前処理手順を実行します\n",
    "一定の機能、欠損値の正規化、再スケーリング、処理。彼らは、ピアソンの相関係数とターゲットとの相互検証に基づいて特徴を選択します。 specif1での試行\n",
    "クラスの不均衡と主成分分析の取り扱いは無益でした。成功すると、var15 <23のようなヒューリスティックルールが追加され、ターゲットは0になります。主なモデルは決定木に基づいています。\n",
    "\n",
    "0.8249：Wang（2016）は、これに比較的鈍感な決定木のみを使用するつもりなので、前処理はほとんど適用しません。彼は、基準として勾配ブースティング分類器で重要な特徴を幅広く選択しています。その後、機能ごとのパーセンタイル変更を追加し、選択を再度適用します。パラメータは、粗いアプローチから細かいアプローチまで、一度に1つずつ繰り返しトレーニングされます。 Adaboost、Bagging Classifier、Extra Trees Classifier、Gradient Boosting、Random Forest、XGBoostが組み合わされて、最終的なスコアにつながります。\n",
    "\n",
    "0.824332：Kumar（2015）は、トップ10の機能、主成分分析と組み合わせたサポートベクターマシンで線形回帰を試みますが、最初は限られた成功しかありません。ニューラルネットワーク、調整されたランダムフォレスト、およびXGBoostにより、より良い結果が得られます。 XGBoostは明らかに最良の候補と見なされ、上位N個の機能で使用されます。これにより、5つを超える機能は交差検証スコアにごくわずかな改善しか加えられないことが明らかになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train set consists of 76020 observations and 370 features plus 1 binary target. The test set has a roughly equal amount of 75818 observations with the same features. There is a large imbalance with 96.04% being 0, meaning the customer was not dissatisfied and 3.96% being 1, signifying that the customer was dissatisfied. This is in line with the expectation of the customer satisfaction of a successful bank. There are no missing values in the train or test set, but some values might encode ’missing’. There are only numeric or possibly categorical features. No features seem to have substantial outliers.\n",
    "\n",
    "The dataset is semi-anonymized, so it is unclear what a feature represents. The only clue we have is a header with a name for each feature that is clearly not randomly determined. For illustrative purposes, the first seven names are given in order from left to right: ID, var3, var15, imp_ent_var16_ult1, imp_op_var39_comer_ult1, imp_op_var39_comer_ult3 and imp_op_var40_comer_ult1. Some of these words appear to be abbreviations for Spanish words like ’imp’ for importe or amount. A non comprehensive dictionary is discussed on the Kaggle forum (Andreu, 2015). On first glance, one can also infer that imp_op_var39_comer_ult1 and imp_op_var39_comer_ult3 are probably related and they are likely not related to var3. Looking at the distribution of the data can confirm these suspicions. We first distinguish some groups based on their name and broadly research each group in turn. Then we look into individual features that do not fit into a group in more depth. Aside from the clearly irrelevant ID variable, this comprises all the features. This is more practical than discussing all 370 features thoroughly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "トレインセットは、76020の観測値と370のフィーチャと1つのバイナリターゲットで構成されます。テストセットには、ほぼ同じ量の同じ機能を持つ75818の観測値があります。大きな不均衡があります\n",
    "96.04％は0であり、顧客は不満ではなかったことを意味し、3.96％は1であり、顧客が不満であることを示しています。これは、成功した銀行の顧客満足度の期待と一致しています。トレインまたはテストセットには欠損値はありませんが、一部の値は「欠損」をエンコードする場合があります。数値またはカテゴリの特徴のみがあります。実質的な外れ値を持つ機能はないようです。\n",
    "\n",
    "データセットは半匿名化されているため、機能が何を表しているのかは不明です。私たちが持っている唯一の手がかりは、明らかにランダムに決定されていない各機能の名前を含むヘッダーです。説明のために、最初の7つの名前は、左から右に順に付けられています。ID、var3、var15、imp_ent_var16_ult1、imp_op_var39_comer_ult1、imp_op_var39_comer_ult3、imp_op_var40_comer_ult1これらの単語の一部は、輸入品または金額を表す「imp」のようなスペイン語の単語の略語のようです。包括的な辞書は、Kaggleフォーラム（Andreu、2015年）で議論されています。一見すると、imp_op_var39_comer_ult1とimp_op_var39_comer_ult3はおそらく関連しており、それらはvar3とは関連がないと推測できます。データの分布を見ると、これらの疑いを確認できます。まず、名前に基づいていくつかのグループを区別し、各グループを順番に大まかに調べます。次に、グループに収まらない個々の機能について詳しく説明します。明らかに無関係なID変数は別として、これはすべての機能を備えています。これは、370の機能すべてを徹底的に説明するよりも実用的です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Feature Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sheer number of features in this dataset makes it hard to individually analyze and discuss each feature, so instead similar groups have been identified in the dataset, assisted by their corresponding names. In Table 1 it is visible on which substrings has been filtered. There is certain overlap between the groups as all ’Meses’ features are also ’Num’ features for example and all ’Delta’\n",
    "features are also either ’Imp’ or ’Num’ features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットの機能の数が多いと、各機能を個別に分析して説明することが難しくなるため、代わりに、対応する名前を利用して、類似したグループがデータセットで識別されました。 表1では、どの部分文字列がフィルタリングされたかが表示されます。 たとえば、すべての「メス」機能は「数字」機能でもあり、すべて「デルタ」でもあるため、グループ間で特定の重複があります。\n",
    "機能も「インプ」または「数値」のいずれかの機能です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The substring ’Num’ likely stands for numeric variables. Typically, excluding the ’Delta’ and ’Meses’ subsets, these have values 0, 3, 6, 9 and further multiples of 3 as most common observations. These could indicate quarters for example. 0 and 3 tend to be most common and the distribution is usually unbalanced. The substring ’Ind’ likely stands for indicator variables as all of them are 0 or 1. The distribution is usually unbalanced, but not consistently towards 1 or 0.\n",
    "\n",
    "The substring ’Saldo’ suggest the current actual amount on balance for certain financial products. A lot of these variables have an overwhelming amount of zero’s, possibly being finished financial products or products that are not utilized in the first place. Other values are typically numeric and are of large scale like 6119500. Some values are also negative further providing evidence that this is a ’balance’ type variable. Very similarly, ’Imp’ can stand for Importe (Spanish for amount) and the distributions match this conjecture. Notable is that the scale tends to be smaller, so perhaps ’Saldo’ is a sum of consecutive periods.\n",
    "\n",
    "The substring ’Delta’ signifies a difference of some kind, but the variable’s distributions match ratio’s, so it is possibly the ratio of an amount between a certain time period. Also here there is a massive imbalance towards the value 0. All ’Meses’ variables are ’Num’ variables, but are specifically taken as a subgroup, because they have a wildly different distribution. ’Meses’ is Spanish for months and in the data these variables only take values 0, 1, 2 and 3. Some of the ’Meses’ variables are even fairly balanced, which is fairly unique within this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部分文字列「Num」は、おそらく数値変数を表します。通常、「Delta」と「Meses」のサブセットを除くと、これらは0、3、6、9の値と、最も一般的な観測値である3の倍数を持ちます。たとえば、これらは四半期を示すことができます。 0と3が最も一般的で、分布は通常不均衡です。部分文字列「Ind」は、すべて0または1であるため、インジケーター変数を表す可能性があります。通常、分布は不均衡ですが、一貫して1または0に向かっているわけではありません。\n",
    "\n",
    "サブストリング「Saldo」は、特定の金融商品の残高の現在の実際の金額を示しています。これらの変数の多くは圧倒的な量のゼロを持ち、おそらく財務が終了しています\n",
    "製品またはそもそも利用されていない製品。他の値は通常数値で、6119500のような大規模です。一部の値も負であり、これが\n",
    "「バランス」タイプの変数です。非常に同様に、「インプ」はインポート（スペイン語で金額）を表すことができ、分布はこの推測に一致します。注目すべきは、規模が小さくなる傾向があるため、「サルド」は連続した期間の合計である可能性があることです。\n",
    "\n",
    "サブストリング「Delta」はある種の違いを示しますが、変数の分布は比率と一致するため、特定の期間の金額の比率である可能性があります。また、ここでは値0に対して大きな不均衡があります。すべての「Meses」変数は「Num」変数ですが、分布が大きく異なるため、特にサブグループとして扱われます。 「メス」はスペイン語であり、データではこれらの変数の値は0、1、2、3のみです。一部の「メス」変数はかなりバランスが取れており、このデータセット内でかなりユニークです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Individual Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These features all have a very short name and could be considered a group of their own. However upon closer inspection of at minimum two of them, it becomes apparent that they are clearly not related in the same manner as the previous groups of features. This individuality also means we need to consider each feature separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これらの機能はすべて非常に短い名前を持ち、独自のグループと考えることができます。 ただし、少なくとも2つを詳しく調べると、以前の機能グループと同じように関連していないことが明らかになります。 この個性は、各機能を個別に検討する必要があることも意味します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 var3(Nationality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var3 is suspected to be nationality or country of residence. 208 Unique countries sounds like a plausible number that the bank can supply. 74165 observations are 2, which probably stand for the United States, the main market for this particular bank. A binary feature var3_most_common is made to put emphasis on this, which is 1 if var3 is equal to 2 and 0 otherwise. -999999 likely encodes for missing values and another binary feature var3_missing accounts for this. After this feature is made the -999999 values are replaced by the most commonly occurring value 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var3は国籍または居住国であると疑われています。 208のユニークな国々は、銀行が供給できるもっともらしい数字のように聞こえます。 74165の観測値は2であり、おそらくこの銀行の主要市場である米国を表しています。 これを強調するために、バイナリ機能var3_most_commonが作成されています。これは、var3が2に等しい場合は1、それ以外の場合は0です。 -999999は欠損値をエンコードする可能性が高く、別のバイナリ機能var3_missingがこれを説明します。 この機能が作成された後、-999999の値は、最も一般的に発生する値2に置き換えられます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 var15(Age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var15 is suspected to represents age as the minimum and maximum values are respectively 5 and 105, but the majority of the data is over 21. This data seems very biased to younger people and perhaps 23 is filled in if the age is unknown. For this reason we make another binary feature var15_most_common, which is 1 if var15 is equal to 23 and 0 otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "var15は、最小値と最大値がそれぞれ5と105であるため、年齢を表すと思われますが、データの大部分は21を超えています。このデータは若い人には非常に偏っていると思われ、年齢が不明な場合はおそらく23が入力されます。 このため、別のバイナリ機能var15_most_commonを作成します。これは、var15が23に等しい場合は1、それ以外の場合は0です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 var21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all variables have an easy interpretation in this anonymized dataset and var21 is a prime example. It is highly imbalanced and the non-zero values do not give off a likely meaning. Nevertheless it could still possibly be important, as it is clearly distinct from other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この匿名化されたデータセットでは、すべての変数が簡単に解釈できるわけではなく、var21が主な例です。 それは非常に不均衡であり、ゼロ以外の値はありそうな意味を与えません。 それでも、他の変数と明確に区別されるため、それはおそらく重要である可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 var36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not much to be said about this particular variable, except that it is very likely categorical. One-hot encoding is applied such that it can be better understood by our classifiers. In the same vein, 99, which likely stands for missing values, is encoded properly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この特定の変数については、カテゴリカルである可能性が非常に高いことを除いて、それほど言及する必要はありません。 ワンホットエンコーディングは、分類子がより理解しやすいように適用されます。 同じように、欠損値を表す可能性が高い99は正しくエンコードされます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 var38(Mortgage Value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This distribution ranges from high to low positive numbers with a very large number of the same value 117310. It is our conjecture that this represents the mortgage value of a customer or at least some kind of value indicating variable. If it is unknown for whatever reason the country average is instead filled in. For this reason we create a dummy variable var38_most_common that remembers this information. It is 1 if var38 is 117310 and 0 otherwise. We visualize the distribution of the known values by making a histogram, excluding 117310 and cutting of the range at 350000, which excludes 1559 more observations, in Figure 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "この分布は、高い値から低い値までの範囲であり、非常に大きな数の同じ値117310を持っています。これは、顧客の住宅ローンの値、または少なくともある種の値を示す変数を表すと推測されます。 何らかの理由で不明な場合は、代わりに国の平均が入力されます。このため、この情報を記憶するダミー変数var38_most_commonを作成します。 var38が117310の場合は1、それ以外の場合は0です。 図2では、117310を除外してヒストグラムを作成し、さらに1559の観測を除外して350000で範囲を切り取って、既知の値の分布を視覚化しています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 num_var4 (Number of Bank Products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to dmi3kno (2015) this variable represents the number of bank products this client currently has with the bank. The distribution suggests that fewer people have multiple products with the bank and those tend to not be dissatisfied, giving this explanatory value. This is also intuitive, as clients investing multiple times probably have a good relationship with the bank and conversely the bank has more information to satisfy their client appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dmi3kno（2015）によると、この変数は、このクライアントが現在銀行に持っている銀行商品の数を表します。 分布は、銀行で複数の商品を持っている人が少なく、それらは不満が出ない傾向があることを示唆しており、この説明的な価値を与えています。 複数回投資するクライアントはおそらく銀行と良好な関係を築いており、逆に銀行はクライアントを適切に満足させるためのより多くの情報を持っているため、これも直感的です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On first glance the data is fairly clean, however there are definite problems for running certain features and observations through a machine learning algorithm. Figure 4 demonstrates the order that the cleaning steps were taken in. The left number represents the number of observations and the right the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一見するとデータはかなりクリーンですが、特定の機能や観測を機械学習アルゴリズムで実行することには明確な問題があります。 図4は、クリーニング手順が実行された順序を示しています。左側の数字は観察の数を表し、右側はフィーチャの数を表します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 34 features that are one constant value (zero for all checked cases). These features that do not vary at all cannot teach our classifier anything meaningful, so all features that have a standard deviation of zero are omitted. 29 features are exact duplicates of one another as well. We remove the redundancy by removing all but the first feature of a duplicate group. Note that the order of these cleaning procedures influences the number of removed features.\n",
    "\n",
    "Some features have as little as 2 non-zero values. We categorize features that have very few nonzero values as uninformative for our classifier. We remove 104 features from the data by arbitrarily drawing a line at 100, effectively removing all features that have less than 100 observations that are not zero. Several of these were checked by eye and having a non-zero value was not very discriminatory regarding the Target value. For contextual purposes we show in Figure 5 what different choices would have meant for the dimension of the feature set. Finally we remove the index and in doing so assume the training data does appear randomly to us and not in a particular order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1つの定数値（チェックされたすべてのケースでゼロ）である34の機能があります。まったく変化しないこれらの機能は、分類器に意味のあるものを教えることができないため、標準偏差がゼロのすべての機能は省略されます。 29の機能も、互いにまったく同じです。重複グループの最初の機能を除いてすべてを削除することにより、冗長性を削除します。注意してください\n",
    "これらのクリーニング手順の順序は、削除される機能の数に影響します。\n",
    "\n",
    "一部の機能には、ゼロ以外の値が2つしかありません。ゼロ以外の値がほとんどない特徴は、分類器にとって有益ではないものとして分類します。データから104の機能を任意に削除します\n",
    "100に線を引き、0でない観測値が100未満のすべてのフィーチャを効果的に削除します。これらのいくつかは目でチェックされ、ゼロ以外の値を持つことは、ターゲット値に関してあまり差別的ではありませんでした。状況に応じて、図5に、機能セットのディメンションにどのような選択肢があったかを示します。最後に、インデックスを削除します。その際、トレーニングデータが特定の順序ではなくランダムに表示されると想定します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are also 4912 exact duplicates in features of the 76020 observations in the training data. Even worse, 109 of those duplicates have a differing target, which can only possibly ’confuse’a classifier. Although it can also be said that it will simply attach less confidence towards the importance of these observations, but to avoid the issue altogether these are all excluded from the dataset. The first of the duplicates that have the same target is kept around and 71108 observations remain after this procedure.\n",
    "\n",
    "The three ’Delta’ variables that are leftover are still relatively uninformative. They also do not appear as having great predictive power in any related literature studied. For these reasons they are also removed. They are the only variable group for which this is deemed appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、トレーニングデータの76020観測の特徴には、4912の正確な重複があります。 さらに悪いことに、これらの重複のうち109は異なるターゲットを持っているため、分類子を「混乱」させる可能性があります。 これらの観測の重要性に対する信頼度が低くなると言うこともできますが、問題を完全に回避するために、これらはすべてデータセットから除外されています。 同じターゲットを持つ最初の重複は保持され、71108の観測がこの手順の後に残ります。\n",
    "\n",
    "残っている3つの「デルタ」変数は、まだ比較的情報がありません。 また、調査された関連文献では、それらは優れた予測力を備えているようには見えません。 これらの理由により、それらも削除されます。 これらは、これが適切であると見なされる唯一の可変グループです。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation can be a powerful tool in machine learning. One of a pair of heavily correlated predictors can be removed without harming the predictive power of a model. Also very high absolute correlation with the target can indicate that this is an important variable. We apply the former and we look at the top features in the sense of being correlated with the target. We first apply normalization, where appropriate, to scale all variables between 0 and 1. We note that several of the features are hugely imbalanced and this type of scaling does not damage that. A feature X will become normalized feature Z with the following formula:\n",
    "\n",
    "After applying this to var15, var38, ’Num’s, ’Imp’s and ’Saldo’s, we plot the following Correlation matrix in Figure 6 and zoom in in Figure 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相関は機械学習の強力なツールになり得ます。 モデルの予測力を損なうことなく、強く相関する2つの予測子の1つを削除できます。 また、ターゲットとの絶対相関が非常に高い場合は、これが重要な変数であることを示している可能性があります。 前者を適用し、ターゲットと相関しているという意味で上位の機能を調べます。 まず、必要に応じて正規化を適用し、すべての変数を0から1の間でスケーリングします。いくつかの機能は非常に不均衡であり、このタイプのスケーリングはそれに影響を与えません。 特徴Xは、次の式で正規化された特徴Zになります。\n",
    "\n",
    "これをvar15、var38、「Num」、「Imp」、「Saldo」に適用した後、図6に次の相関行列をプロットし、図7にズームインします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is clearly visible that for instance imp_op_var39_comer_ult1 is heavily correlated with imp_op_var39_comer_ult3, further confirming that similar variable names are related, justifying the grouping of variables done earlier. Some features even have a correlation extremely close to 1 with each other like num_var1_0 and ind_var1_0 with 0.9988. All variable pairs that have higher absolute correlation than a conservative 0.99 are filtered out and the first of the pairs is deleted. An extension of this could delete one of the pair based on lower absolute correlation with the target. This removes 29 features and brings the cleaned dataset to 171 features total It is visualized in Figure 8 what different correlation thresholds would mean for the dimensions of the feature set. We have been relatively conservative as the tree-based algorithms we use are adept at handling correlated features and the dataset is already comparatively small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ここでは、たとえば、imp_op_var39_comer_ult1がimp_op_var39_comer_ult3と強く相関していることがわかり、類似の変数名が関連していることがさらに確認され、以前に行われた変数のグループ化が正当化されます。 0.9988のnum_var1_0やind_var1_0のように、いくつかの機能は互いに非常に1に近い相関関係さえ持っています。 保守的な0.99よりも高い絶対相関を持つすべての変数のペアは除外され、最初のペアが削除されます。 これを拡張すると、ターゲットとのより低い絶対相関に基づいて、ペアの1つが削除される可能性があります。 これにより、29のフィーチャが削除され、クリーンアップされたデータセットが合計171のフィーチャになります。図8に、フィーチャセットのディメンションに対するさまざまな相関しきい値の意味を示します。 私たちが使用するツリーベースのアルゴリズムは相関する特徴の処理に長けており、データセットはすでに比較的小さいため、私たちは比較的保守的でした。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Furthermore some of the top correlations are showcased in Table 8. It is likely that these will be the important predictors later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さらに、上位の相関関係のいくつかを表8に示します。これらは後で重要な予測因子になる可能性があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset mostly lent itself for decoding what the existing data meant and making sure it is an appropriate format for machine learning algorithms. Nevertheless this led to the creation of some features, that were mentioned before, to accommodate expected oddities in the data. For instance the feature var38_most_common was created to ensure that the algorithm can recognize that this is likely a unique value outside of the numerical order that var38 has. Outside of the ones mentioned before, the ’Meses’ group was completely one-hot encoded, because they were small enough to warrant such an approach and seemed on first glance categorical.\n",
    "\n",
    "Furthermore it is noticeable that the data contains a lot of zero’s. This usually stands for a lack of information or interaction and precisely that lack of knowing thy customer could hold predictive value for determining if the customer will possibly be dissatisfied in the future. For this reason n0 was created, which simply sums the number of zero’s that appear in the row. (dmi3kno, 2015) Special care is taken to not include the Target variable as this is a form of information leakage\n",
    "which disturbs the learning process of the models. Conversely a n1 was created that should signify that the bank does know their customer and has a lot of interaction with them. This would be different, and not redundant in that way, than creating a variable that simply sums all spots in the row that are not zero. This brings the total dimensions of our training set to 71108 observations and 215 features to start the modeling process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータセットは、既存のデータが何を意味するかをデコードし、それが機械学習アルゴリズムに適切な形式であることを確認するために、ほとんど貸し出しました。それにもかかわらず、これにより、データで予想される奇妙さを吸収するために、前述のいくつかの機能が作成されました。たとえば、機能var38_most_commonは、アルゴリズムが、これがvar38が持つ順序の外の一意の値である可能性が高いことを確実に認識できるようにするために作成されました。前述のグループ以外では、「メセス」グループは完全にワンホットエンコードされました。これは、そのようなアプローチを正当化するのに十分なほど小さく、一見するとカテゴリに見えたためです。\n",
    "\n",
    "さらに、データには多くのゼロが含まれていることがわかります。これは通常、情報または対話の欠如を表しており、正確には、顧客を知ることの欠如が、将来顧客が不満を抱く可能性があるかどうかを判断するための予測値を保持する可能性があります。このため、行に表示されるゼロの数を単純に合計するn0が作成されました。 （dmi3kno、2015）これは情報漏えいの一形態であるため、Target変数を含めないように特別な注意が払われています\n",
    "これはモデルの学習プロセスを妨害します。逆に、銀行が顧客を知っており、顧客とのやり取りが多いことを示すn1が作成されました。これは、ゼロではない行のすべてのスポットを単純に合計する変数を作成する場合とは異なり、そのように冗長ではありません。これにより、トレーニングセットの合計次元が71108の観測と215の特徴になり、モデリングプロセスが開始されます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Modeling\n",
    "## 5.1 Performance Measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance measure of this Kaggle competition is the area under the receiver operating characteristic curve, AUROC or AUC for short. This metric deals well with the imbalance that is typical in churn prediction. (Burez and van den Poel, 2009) We build up to this concept by considering some simpler notions first. (Dernoncourt, 2015) If we consider a binary classifier we have four possible outcomes when we use it make a binary prediction and we call the collection of this a confusion matrix and an example is shown in Figure 9.\n",
    "\n",
    "- True negative: We predict 0 and the class is actually 0.\n",
    "- False negative: We predict 0 and the class is actually 1.\n",
    "- True positive: We predict 1 and the class is actually 1.\n",
    "- False positive: We predict 1 and the class is actually 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このKaggle競争のパフォーマンス指標は、レシーバーの動作特性曲線の下の領域、略してAUROCまたはAUCです。 このメトリックは、チャーン予測で一般的な不均衡をうまく処理します。 （Burezとvan den Poel、2009）まず、いくつかの単純な概念を検討することで、この概念を構築します。 （Dernoncourt、2015）バイナリ分類器を検討すると、バイナリ予測を使用して4つの可能な結果が得られ、このコレクションを混同行列と呼び、例を図9に示します。\n",
    "\n",
    "- 真陰性：0を予測し、クラスは実際には0です。\n",
    "- 偽陰性：0を予測し、クラスは実際には1です。\n",
    "- 真陽性：1を予測し、クラスは実際には1です。\n",
    "- 誤検知：1を予測し、クラスは実際には1です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the following ratio’s. The True Positive Rate corresponds to the proportion of positive data points that are correctly considered as positive, with respect to all positive data points. The higher the better, all else equal. The False Positive Rate corresponds to the proportion of negative data points that are incorrectly classified as positive, with respect to all negative data points. The lower the better all else equal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下の比率を定義します。 真陽性率は、すべての陽性データポイントに対する、陽性と正しく見なされる陽性データポイントの割合に対応します。 高いほど良い、他のすべては等しい。 誤検出率は、すべての負のデータポイントに対して、誤って正として分類された負のデータポイントの割合に対応します。 値が小さいほど、他のすべての条件が等しくなります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binary classifiers usually predict with what probability they expect 1 to occur. The threshold where a high probability leading to predicting a 1 lies is an arbitrary decision. It is possible to consider every single possible threshold and plot the corresponding pair of TPR and FPR’s of the resulting predictions in a ROC curve plot. An example is given in Figure 10. To obtain a single performance metric we can take the area under the ROC curve and effectively take into account both TPR and FPR. The baseline for this metric lies at 0.5, where we predict completely randomly. Anything performing worse can simply be inverted to do better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "バイナリ分類子は通常、1が発生すると予測する確率を予測します。 1の予測につながる高い確率が存在するしきい値は、任意の決定です。 可能なすべてのしきい値を検討し、ROC曲線プロットで結果の予測の対応するTPRとFPRのペアをプロットすることが可能です。 例を図10に示します。単一のパフォーマンスメトリックを取得するには、ROC曲線の下の領域を取得し、TPRとFPRの両方を効果的に考慮することができます。 このメトリックのベースラインは0.5にあり、完全にランダムに予測します。 パフォーマンスが悪いものは、単に逆にしてより良くすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Solution Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use 3 different methods to come to a solution: Logistic Regression, Random Forest from Scikit Learn (Pedregosa et al., 2011) and XGBoost (Chen and Guestrin, 2016). We apply 10-fold stratified crossvalidation on the train set to compare models internally, consequently fit the best model on the entirety of the train data and then predict labels for the test set and validate these on the Kaggle site for the final score. Stratification in this context refers to ensuring that each fold of the crossvalidation has a roughly equal distribution of classes as the original whole data set. Stratification tends to improve the accuracy of the crossvalidation as means of testing when dealing with imbalanced data. (Kohavi, 1995)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "解決策には、ロジスティック回帰、Scikit Learnのランダムフォレスト（Pedregosa et al。、2011）およびXGBoost（ChenとGuestrin、2016）の3つの異なる方法を使用しています。 トレインセットに10重の層別交差検証を適用してモデルを内部で比較し、結果としてトレインデータ全体に最適なモデルを適合させてから、テストセットのラベルを予測し、Kaggleサイトでこれらを検証して最終スコアを求めます。 この文脈での層別化とは、交差検証の各分割が、元のデータセット全体とほぼ等しいクラスの分布を持つことを保証することを指します。 階層化は、不均衡なデータを処理するときのテストの手段として、相互検証の精度を向上させる傾向があります。 （コハビ、1995）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression is a relatively ’simple’ machine learning algorithm and we expect fast, but not great results. It tries to attach the best constant values to how features interact with the target, based on the train set, minimizing an error term. It then applies this same formula to the test data set. It is pursued here as a baseline in order to compare to more sophisticated models. For more details see (Bishop, 2006)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰は比較的「単純な」機械学習アルゴリズムであり、高速ではあるが素晴らしい結果は期待できない。 トレインセットに基づいて、フィーチャがターゲットと相互作用する方法に最適な定数値を付加して、エラー項を最小限に抑えようとします。 次に、この同じ式をテストデータセットに適用します。 ここでは、より洗練されたモデルと比較するためのベースラインとしてそれを追求します。 詳細については、（Bishop、2006）を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following two algorithms rely on multiple decision trees. This section roughly describes what a decision tree is. See (Breiman et al., 1984) for more details. To illustrate the concept of a decision tree we run a basic tree classifier implementation on our data and obtain Figure 11.\n",
    "\n",
    "The concept is fairly simple. If a prediction needs to be made, go from the top of the tree to the bottom. Go left at the top if var15 is lower than 0.215, right otherwise. Repeat this process for all nodes until a leaf is reached and the prediction made corresponds to the class label of that leaf. This tree is constructed by at each depth level greedily finding the best feature to split on, maximizing information gain via the Gini impurity. Let p0 be the proportion of observations that belong to class 0 and let p1 be the proportion of observations that belong to class 1 out of all observations.\n",
    "\n",
    "This metric is an example of how to measure how pure a split is. It is more pure the lower it is with minimum 0 and maximum 0.5. A split is purer if in the branches the ratio of positive to negative examples is close to 0 or 1 or in other words the split is highly discriminatory. The maximum depth of this tree is set at 2 to keep it tractable and this effectively also keeps it from overfitting. A decision tree can otherwise perfectly match a training set, which does not generalize well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次の2つのアルゴリズムは、複数の決定木に依存しています。このセクションでは、決定木とは何かについて大まかに説明します。詳細については、（Breiman et al。、1984）を参照してください。決定木の概念を説明するために、データに対して基本的なツリー分類器の実装を実行し、図11を取得します。\n",
    "\n",
    "コンセプトはかなりシンプルです。予測を行う必要がある場合は、ツリーの上部から下部に移動します。 var15が0.215未満の場合は左上に移動し、それ以外の場合は右に移動します。葉に到達し、行われた予測がその葉のクラスラベルに対応するまで、すべてのノードに対してこのプロセスを繰り返します。このツリーは、各深度レベルで分割するのに最適な機能を貪欲に見つけ、Gini不純物を介して情報ゲインを最大化することによって構築されます。すべての観測値のうち、クラス0に属する観測値の割合をp0とし、クラス1に属する観測値の割合をp1とします。\n",
    "\n",
    "このメトリックは、分割がどれだけ純粋かを測定する方法の例です。最小値が0で最大値が0.5の場合、より純粋です。分岐内の正の例と負の例の比率が0または1に近い場合、つまり分割が非常に差別的である場合、分割はより純粋です。このツリーの最大の深さは2に設定されて扱いやすくなり、これにより効果的に過剰適合が防止されます。それ以外の場合、決定木はトレーニングセットと完全に一致する可能性があり、一般化が不十分です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Random Forest\n",
    "The Random Forest model generates multiple decision trees. (Breiman, 2001) Only a subset of predictive features is now considered during each split that is randomly selected. The decision trees lead to one single prediction together by averaging all the predictions they give individually.\n",
    "\n",
    "The parameters of a Random Forest model are really important and need to be tuned appropriately. N_ESTIMATORS determines the number of trees in the forest. MAX_FEATURES controls the maximum random amount of features to consider when determining a best split during the algorithm. MAX_DEPTH limits the depth of a tree in the random forest. MIN_SAMPLES_SPLIT determines the minimum amount of observations that need to be in a node for it to be considered for splits. MIN_SAMPLES_LEAF constrains that leaf nodes have at least this number of observations. N_JOBS controls the number of processors. Trees in a random forest can be made in parallel, so the more cores working, the less computation time needed. CLASS_WEIGHT can be set to ’balanced’ to deal with imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ランダムフォレストモデルは、複数の決定木を生成します。 （Breiman、2001）ランダムに選択された各分割中に、予測機能のサブセットのみが考慮されるようになりました。決定木は、それらが個別に与えるすべての予測を平均することにより、1つの予測をまとめて導きます。\n",
    "\n",
    "ランダムフォレストモデルのパラメーターは非常に重要であり、適切に調整する必要があります。 N_ESTIMATORSは、フォレスト内のツリーの数を決定します。 MAX_FEATURESは、アルゴリズム中に最適な分割を決定するときに考慮すべきランダムな最大機能量を制御します。 MAX_DEPTHは、ランダムフォレスト内のツリーの深さを制限します。 MIN_SAMPLES_SPLITは、ノードを分割と見なすためにノードに存在する必要がある観測の最小量を決定します。 MIN_SAMPLES_LEAFは、リーフノードに少なくともこの数の観測値があることを制限します。 N_JOBSはプロセッサの数を制御します。ランダムフォレスト内のツリーは並行して作成できるため、より多くのコアが機能するほど、必要な計算時間は少なくなります。 CLASS_WEIGHTを「バランス」に設定すると、不均衡なデータセットを処理できます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.4 XGBoost\n",
    "XGBoost is a method where the outcome is formed by an combination of multiple trees. The trees are build iteratively. Every time a new tree is built it focuses on parts where the previous ones make mistakes, by assigning higher weights to these instances. This stands in contrast to Random Forest, where trees are made independently from each other.\n",
    "\n",
    "The parameters are again of grave importance and there are even more. N_ESTIMATORS and MAX_DEPTH are the same as with the Random Forest model. LEARNING_RATE is a parameter that controls the speed and preciseness of the model. The lower it is, the more accurate your model becomes, but the more rounds it needs to converge. It represents a constant times how much the next tree built affects current predictions. SUBSAMPLE stands for the fraction of observations to be sampled randomly. COLSAMPLE_BYTREE denotes the fraction of features to take into consideration during the random sampling for each tree. MIN_CHILD_WEIGHT defines the minimum sum of weights of all observations required in a child. SCALE_POS_WEIGHT is a parameter to\n",
    "combat imbalancedness. XGBoost directly avoids overfitting by promoting simplicity of models in the objective via regularization, unlike Random Forest that only limits the way trees can grow by imposing restraints. (Chen, 2014)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoostは、複数のツリーの組み合わせによって結果が形成される方法です。木は繰り返し構築されます。新しいツリーが構築されるたびに、これらのインスタンスに高い重みを割り当てることにより、前のツリーが誤りを犯した部分に焦点が当てられます。これは、木が互いに独立して作られるランダムフォレストとは対照的です。\n",
    "\n",
    "パラメータは再び非常に重要であり、それ以上のものがあります。 N_ESTIMATORSとMAX_DEPTHは、ランダムフォレストモデルと同じです。 LEARNING_RATEは、モデルの速度と精度を制御するパラメーターです。値が低いほど、モデルはより正確になりますが、収束が必要なラウンドが多くなります。これは、次のツリーが現在の予測にどの程度影響するかを一定の時間で表します。 SUBSAMPLEは、ランダムにサンプリングされる観測の割合を表します。 COLSAMPLE_BYTREEは、各ツリーのランダムサンプリング中に考慮する特徴の割合を示します。 MIN_CHILD_WEIGHTは、子で必要なすべての観測の重みの最小合計を定義します。 SCALE_POS_WEIGHTは、戦闘の不均衡。 XGBoostは、制限を課すことによって木が成長する方法を制限するだけのランダムフォレストとは異なり、正規化によって目的のモデルの単純化を促進することにより、過剰適合を直接回避します。 （陳、2014）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REG_ALPHA is a parameter for l1 regularization. LAMBDA is a parameter for l2 regularization. GAMMA is a regularization parameter that multiplies itself with the number of leaves. This regularization is in place to penalize the objective for building overtly complex trees to avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "REG_ALPHAは、l1正則化のパラメーターです。 LAMBDAは、l2正則化のパラメーターです。\n",
    "GAMMAは、葉の数を乗算する正則化パラメーターです。 この正規化は、過度に複雑なツリーを構築して過剰適合を回避するという目的にペナルティを課すために実施されています。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Results\n",
    "## 6.1 Tuning RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to determine what set of parameters is optimal for a specific problem. We utilize the GridSearchCV() (Buitinck et al., 2013) function with 5-fold stratified crossvalidation and scoring option area under the ROC curve to come to an answer. This basically boils down to trying all possible combinations of a set of predetermined parameter spaces. The parameter spaces and results of the grid search are shown in Table 9. These parameter spaces were seen as the optimal tradeoff between computation time and accurately tuning the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "特定の問題に最適なパラメーターのセットを決定することは困難です。 ROC曲線の下の5重の層別交差検証およびスコアリングオプションエリアでGridSearchCV（）（Buitinck et al。、2013）関数を使用して、答えを導き出します。 これは基本的に、事前に設定されたパラメータスペースのセットのすべての可能な組み合わせを試すことです。 グリッド検索のパラメーター空間と結果を表9に示します。これらのパラメーター空間は、計算時間とモデルの正確な調整の間の最適なトレードオフと見なされました。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the aforementioned best parameter set we fit the model on the training data and make a plot of how relevant a specific feature is in Figure 12. These importances represent the total Gini impurity decrease weighted by the probability of reaching a node containing this feature, averaged over all trees. We can be pleased to see that several of the features we created like var15_most_common seem to be significant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前述の最適なパラメーターセットを使用して、モデルをトレーニングデータに適合させ、特定の機能の関連性を図12にプロットします。これらの重要性は、この機能を含むノードに到達する確率によって重み付けされたGini不純物の減少の合計を平均したものです すべての木の上。 var15_most_commonのように作成したいくつかの機能が重要であるように見えることを嬉しく思います。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also plot one of the many trees the forest model creates in Figure 13, namely the very first one and we can see it is considerable in size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、図13でフォレストモデルが作成する多数の木の1つ、つまり最初の1つをプロットします。これはかなりサイズが大きいことがわかります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Tuning XGBoost\n",
    "The numerous parameters in XGBoost make it intractable to simply apply a grid search and instead we utilize RandomizedSearchCV(). Instead of trying all possible combinations, this function samples a predetermined amount of sets of parameters in the parameter spaces specified. Instead of set values in the parameter space we typically have distributions. We run this once for 75 times and using the results of the first try, narrow the parameter spaces and run it again for 50 times. We first apply 5-fold stratified crossvalidation to compare and the second time we make it more precise by using 8-fold stratified crossvalidation. The results are shown in Table 10. We have chosen these starting ranges as broad ranges around recommended starting parameters in related work and here. (Jain, 2016)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoostの多数のパラメーターにより、単純にグリッド検索を適用するのが難しくなり、代わりにRandomizedSearchCV（）を利用します。 この関数は、考えられるすべての組み合わせを試すのではなく、指定されたパラメータースペース内の所定の量のパラメーターセットをサンプリングします。 パラメータ空間に値を設定する代わりに、通常は分布があります。 これを75回1回実行し、最初の試行の結果を使用して、パラメータースペースを絞り込み、50回再実行します。 最初に5重層別交差検定を適用して比較し、2回目は8重層別交差検定を使用してより正確にします。 結果を表10に示します。これらの開始範囲は、関連する作業およびここで推奨される開始パラメーターを中心とした幅広い範囲として選択しました。 （2016年、ジェーン）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the aforementioned best parameter set we fit the model on the training data and make a plot of how relevant a specific feature is in Figure 14. Like the Random Forest model we can see some made features are relevant. There is also a significant overlap between what is important, which is encouraging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前述の最適なパラメーターセットを使用して、モデルをトレーニングデータに適合させ、図14に特定の機能の関連性をプロットします。ランダムフォレストモデルと同様に、作成された機能の一部が関連していることがわかります。 重要なことの間にもかなりの重複があり、これは励みになります"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also show one of the many trees the XGB model creates in Figure 15, namely a randomly selected tree, which happens to be the 300th tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、XGBモデルが図15に作成する多くのツリーの1つ、つまりランダムに選択されたツリー（たまたま300番目のツリー）も示します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Results\n",
    "There are a number of different performance indicators. Our local stratified 10-fold crossvalidation procedure was used to tune all parameters and select features. Note that a single fold takes up to 10 minutes at most and several operations can be ran in parallel. Kaggle also has a private and public leaderboard score. Approximately half of the submitted test set is used for the private leaderboard score and the other for the public leaderboard score. Since the competition had already completed the difference in these scores is superfluous for us. Nevertheless the complete\n",
    "results are showcased in Table 11.\n",
    "\n",
    "Feature set 1 refers to only the top 30 features that have the highest importance scores according to the XGBoost model that uses all features. Feature set 2 refers to feature set 1 except some variables have been manually removed that seeemed obviously correlated like 'saldo_medio_var5_hace3' and 'saldo_medio_var5_hace2'. The one that was deemed most important by the model was kept. Feature set 3 refers to feature set 2 except adding some of the variables that were highly correlated with the target as seen in section 4.2. For a complete list of all involved features see Appendix A. Note that a single fold takes up to 10 minutes at most and several operations can be\n",
    "ran in parallel."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "さまざまなパフォーマンス指標がいくつかあります。すべてのパラメーターを調整し、機能を選択するために、ローカルの層別10分割交差検証手順を使用しました。単一の折りたたみには最大で10分かかり、複数の操作を並行して実行できることに注意してください。 Kaggleには、プライベートおよびパブリックのリーダーボードスコアもあります。提出されたテストセットの約半分は、プライベートリーダーボードスコアに使用され、残りの半分はパブリックリーダーボードスコアに使用されます。コンテストはすでに完了しているため、これらのスコアの違いは私たちにとっては不要です。それにもかかわらず、完全な\n",
    "結果を表11に示します。\n",
    "\n",
    "機能セット1は、すべての機能を使用するXGBoostモデルに従って、重要度スコアが最も高い上位30の機能のみを参照します。機能セット2は、「saldo_medio_var5_hace3」と「saldo_medio_var5_hace2」のように明らかに相関していると思われる一部の変数が手動で削除されたことを除いて、機能セット1を指します。モデルによって最も重要と見なされたものが保持されました。機能セット3は、機能セット2を指しますが、セクション4.2に示すように、ターゲットと高度に相関したいくつかの変数が追加されています。関連するすべての機能の完全なリストについては、付録Aを参照してください。1回の折りたたみには最大で10分かかり、複数の操作を実行できることに注意してください。\n",
    "並行して走った。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very peculiar that the private leaderboard score is consistently lower. This indicates a leaderboard shakeup, where the train set is not representative enough of the test set. For reference the top public leaderboard score is 0.845325 and the top private leaderboard score is 0.829072. Our scores are in far reach of that, however we did not endeavor to be at the top of the leaderboard and kept the test set like a secret until the end. All data exploration was done on solely the training data and normalization for instance was done using just the observations in the training data. We consider this more realistic as you can more truly validate your conclusions with completely new data, as opposed to the information spillover that happens if we had not done so. In a business sense a singular new client tends to appear, instead of an entire population that can for instance be appropriately normalized. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プライベートリーダーボードのスコアが一貫して低いのは非常に奇妙です。 これは、トレーニングセットがテストセットを十分に代表していないリーダーボードのシェイクアップを示しています。 参考までに、上位のパブリックリーダーボードスコアは0.845325で、上位のプライベートリーダーボードスコアは0.829072です。 私たちのスコアはその範囲にありますが、リーダーボードのトップに立つように努力せず、最後までテストセットを秘密のように保ちました。 すべてのデータ探索はトレーニングデータのみで行われ、たとえば正規化はトレーニングデータの観測のみを使用して行われました。 これを行わなかった場合に発生する情報のスピルオーバーとは対照的に、完全に新しいデータで結論をより正確に検証できるため、これはより現実的であると考えています。 ビジネスの意味では、たとえば適切に正規化できる人口全体ではなく、単一の新しいクライアントが表示される傾向があります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 Conclusion\n",
    "This paper researched how to preemptively understand if customers of Santander will be dissatisfied using Machine Learning. A semi-anonymized dataset, to protect the privacy of the customers, provided difficulties in asserting what could be relevant or not, especially in light of a huge feature set. However a thorough data analysis discerned the meaning and interpretation of several features. A Python implementation utilized the Logistic Regression, Random Forest and XGBoost algorithms, carefully tuned, in order to lead to predictions. Further research could for example employ different solution methods, apply more feature engineering or combine several models\n",
    "instead of trying singular models. More specifically they can increase the computation time that goes into tuning and for example make the correlation filtering dependent on the correlation with the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このペーパーでは、サンタンデールの顧客が機械学習を使用して不満を感じるかどうかを事前に理解する方法を調査しました。 顧客のプライバシーを保護するために半匿名化されたデータセットは、特に巨大な機能セットに照らして、関連性があるかどうかを主張するのに困難をもたらしました。 しかし、徹底的なデータ分析により、いくつかの機能の意味と解釈がわかりました。 Pythonの実装では、予測につながるように、ロジスティック回帰、ランダムフォレスト、XGBoostアルゴリズムを慎重に調整して利用しました。 さらなる研究は、例えば、異なる解決方法を採用する、より多くの特徴エンジニアリングを適用する、またはいくつかのモデルを組み合わせる\n",
    "特異なモデルを試す代わりに。 より具体的には、調整にかかる計算時間を増やし、たとえば、ターゲットとの相関に依存して相関フィルタリングを行うことができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
